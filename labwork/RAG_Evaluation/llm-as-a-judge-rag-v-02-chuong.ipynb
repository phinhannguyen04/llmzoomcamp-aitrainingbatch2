{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfe6db71",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-21T11:08:21.336698Z",
     "iopub.status.busy": "2026-01-21T11:08:21.336069Z",
     "iopub.status.idle": "2026-01-21T11:08:21.339803Z",
     "shell.execute_reply": "2026-01-21T11:08:21.339128Z"
    },
    "executionInfo": {
     "elapsed": 6907,
     "status": "ok",
     "timestamp": 1768356781774,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "1Q2WAABybnfE",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.020823,
     "end_time": "2026-01-21T11:08:21.341173",
     "exception": false,
     "start_time": "2026-01-21T11:08:21.320350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q \\\n",
    "#     torch \\\n",
    "#     transformers>=4.36.0 \\\n",
    "#     langchain>=0.1.0 \\\n",
    "#     langchain-community>=0.0.10 \\\n",
    "#     langchain-huggingface \\\n",
    "#     sentence-transformers>=2.3.0 \\\n",
    "#     faiss-cpu \\\n",
    "#     datasets \\\n",
    "#     pandas \\\n",
    "#     tqdm \\\n",
    "#     huggingface-hub>=0.20.0 \\\n",
    "#     ragatouille \\\n",
    "#     openai>=1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e0e853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T11:08:21.369746Z",
     "iopub.status.busy": "2026-01-21T11:08:21.369225Z",
     "iopub.status.idle": "2026-01-21T11:09:27.101837Z",
     "shell.execute_reply": "2026-01-21T11:09:27.101001Z"
    },
    "papermill": {
     "duration": 65.747811,
     "end_time": "2026-01-21T11:09:27.103574",
     "exception": false,
     "start_time": "2026-01-21T11:08:21.355763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m340.3/340.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m102.6/102.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\r\n",
      "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.47.0 which is incompatible.\r\n",
      "google-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\r\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\r\n",
      "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "fastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\r\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch transformers \\\n",
    "    langchain langchain-community langchain-huggingface langchain-core langchain-openai langchain-text-splitters \\\n",
    "    sentence-transformers tqdm openpyxl \\\n",
    "    openai pandas datasets ragatouille \\\n",
    "    faiss-cpu \\\n",
    "    transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afbc3695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T11:09:27.134294Z",
     "iopub.status.busy": "2026-01-21T11:09:27.133802Z",
     "iopub.status.idle": "2026-01-21T11:09:41.426601Z",
     "shell.execute_reply": "2026-01-21T11:09:41.426024Z"
    },
    "papermill": {
     "duration": 14.310104,
     "end_time": "2026-01-21T11:09:41.428269",
     "exception": false,
     "start_time": "2026-01-21T11:09:27.118165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document as LangchainDocument\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa70ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T11:09:41.458280Z",
     "iopub.status.busy": "2026-01-21T11:09:41.457920Z",
     "iopub.status.idle": "2026-01-21T11:09:44.144263Z",
     "shell.execute_reply": "2026-01-21T11:09:44.143641Z"
    },
    "executionInfo": {
     "elapsed": 909,
     "status": "ok",
     "timestamp": 1768355519331,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "MWYgIE6lbrVp",
    "papermill": {
     "duration": 2.702906,
     "end_time": "2026-01-21T11:09:44.145894",
     "exception": false,
     "start_time": "2026-01-21T11:09:41.442988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from typing import Tuple, Optional, List, Dict, Any\n",
    "import datasets\n",
    "import json\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc68dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T11:09:44.176324Z",
     "iopub.status.busy": "2026-01-21T11:09:44.175372Z",
     "iopub.status.idle": "2026-01-21T11:09:44.196101Z",
     "shell.execute_reply": "2026-01-21T11:09:44.195366Z"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1768355519395,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "Za1E97vObr39",
    "outputId": "91b787ef-f1ac-4ec2-bb2a-b4bb5f3ca56f",
    "papermill": {
     "duration": 0.040838,
     "end_time": "2026-01-21T11:09:44.201305",
     "exception": false,
     "start_time": "2026-01-21T11:09:44.160467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c9bfaa6cc947c495f67c78fa131e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4713b5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T11:09:44.230264Z",
     "iopub.status.busy": "2026-01-21T11:09:44.230022Z",
     "iopub.status.idle": "2026-01-21T11:09:47.572949Z",
     "shell.execute_reply": "2026-01-21T11:09:47.572235Z"
    },
    "executionInfo": {
     "elapsed": 2481,
     "status": "ok",
     "timestamp": 1768355529686,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "OPS8vCFZjYTO",
    "outputId": "a15712cd-9553-43bb-c020-2ca2dd2793f6",
    "papermill": {
     "duration": 3.359005,
     "end_time": "2026-01-21T11:09:47.574323",
     "exception": false,
     "start_time": "2026-01-21T11:09:44.215318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f981210c326f4846b0c3d863063c8db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5f5b8cad5d430a874946917be92a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "huggingface_doc.csv:   0%|          | 0.00/22.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111c197f21424d2b97670459b759f4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f986016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T11:09:47.606166Z",
     "iopub.status.busy": "2026-01-21T11:09:47.605297Z",
     "iopub.status.idle": "2026-01-21T11:09:48.304376Z",
     "shell.execute_reply": "2026-01-21T11:09:48.303790Z"
    },
    "executionInfo": {
     "elapsed": 1385,
     "status": "ok",
     "timestamp": 1768355531075,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "6S1fuDNvkA7s",
    "outputId": "131cf5e3-2e3e-42df-e892-21f2f6433143",
    "papermill": {
     "duration": 0.716269,
     "end_time": "2026-01-21T11:09:48.306168",
     "exception": false,
     "start_time": "2026-01-21T11:09:47.589899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df408e45a1a94628a75cdea677ebe43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document as LangchainDocument\n",
    "\n",
    "langchain_docs = [\n",
    "    LangchainDocument(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
    "    for doc in tqdm(ds)\n",
    "]\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "docs_processed = []\n",
    "for doc in langchain_docs:\n",
    "    docs_processed += text_splitter.split_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8617bd11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T11:09:48.337837Z",
     "iopub.status.busy": "2026-01-21T11:09:48.336943Z",
     "iopub.status.idle": "2026-01-21T11:09:48.593671Z",
     "shell.execute_reply": "2026-01-21T11:09:48.592811Z"
    },
    "executionInfo": {
     "elapsed": 13600,
     "status": "ok",
     "timestamp": 1768355545750,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "gVvchbM7bsFr",
    "outputId": "cd8e66aa-fc47-45f7-f818-c18b1f50149c",
    "papermill": {
     "duration": 0.273898,
     "end_time": "2026-01-21T11:09:48.594959",
     "exception": true,
     "start_time": "2026-01-21T11:09:48.321061",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide an api_key to work with featherless-ai API or log in with `hf auth login`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24/3981408442.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcall_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"This is a test context\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_24/3981408442.py\u001b[0m in \u001b[0;36mcall_llm\u001b[0;34m(inference_client, prompt)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcall_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     response = inference_client.chat_completion(\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mchat_completion\u001b[0;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_body\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         }\n\u001b[0;32m--> 908\u001b[0;31m         request_parameters = provider_helper.prepare_request(\n\u001b[0m\u001b[1;32m    909\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/inference/_providers/_common.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, inputs, parameters, headers, model, api_key, extra_payload)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \"\"\"\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# api_key from user, or local token, or raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# mapped model from HF model ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/inference/_providers/_common.py\u001b[0m in \u001b[0;36m_prepare_api_key\u001b[0;34m(self, api_key)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0;34mf\"You must provide an api_key to work with {self.provider} API or log in with `hf auth login`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: You must provide an api_key to work with featherless-ai API or log in with `hf auth login`."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "llm_client = InferenceClient(\n",
    "    model = repo_id,\n",
    "    timeout=120,\n",
    ")\n",
    "\n",
    "def call_llm(inference_client, prompt: str):\n",
    "    response = inference_client.chat_completion(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1000,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "call_llm(llm_client, \"This is a test context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8125684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:20:38.958016Z",
     "iopub.status.busy": "2026-01-21T07:20:38.957684Z",
     "iopub.status.idle": "2026-01-21T07:20:38.962998Z",
     "shell.execute_reply": "2026-01-21T07:20:38.962227Z",
     "shell.execute_reply.started": "2026-01-21T07:20:38.957987Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1768355850201,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "XGvMf86UjtY7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "QA_generation_prompt = \"\"\"\n",
    "Your task is to write a factoid question and an answer given a context.\n",
    "Your factoid question should be answerable with a specific, concise piece of factual information from the context.\n",
    "Your factoid question should be formulated in the same style as questions users could ask in a search engine.\n",
    "This means that your factoid question MUST NOT mention something like \"according to the passage\" or \"context\".\n",
    "---\n",
    "GOOD EXAMPLES:\n",
    "Context: \"The BERT model was released in 2018 by Google Research. It uses 12 transformer layers.\"\n",
    "Question: When was the BERT model released?\n",
    "Answer: The BERT model was released in 2018.\n",
    "\n",
    "Context: \"The batch size parameter controls how many samples are processed at once. The default value is 32.\"\n",
    "Question: What is the default batch size value?\n",
    "Answer: The default batch size value is 32.\n",
    "\n",
    "BAD EXAMPLES TO AVOID:\n",
    "Question: What does the context say about BERT? (references \"context\")\n",
    "Question: Tell me more about this model. (too vague)\n",
    "Answer: It depends on the use case. (not specific)\n",
    "Answer: BERT is a very important model for NLP. (opinion, not fact from context)\n",
    "---\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Output:::\n",
    "Factoid question: (your factoid question)\n",
    "Answer: (your answer to the factoid question)\n",
    "\n",
    "Now here is the context.\n",
    "\n",
    "Context: {context}\\n\n",
    "Output:::\"\"\"\n",
    "\n",
    "print(\"Running successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0e067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:20:41.935926Z",
     "iopub.status.busy": "2026-01-21T07:20:41.935623Z",
     "iopub.status.idle": "2026-01-21T07:21:16.839358Z",
     "shell.execute_reply": "2026-01-21T07:21:16.838462Z",
     "shell.execute_reply.started": "2026-01-21T07:20:41.935899Z"
    },
    "executionInfo": {
     "elapsed": 21128,
     "status": "ok",
     "timestamp": 1768355996835,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "Xd6ZDIc5j6w2",
    "outputId": "960b4c1d-8407-470b-d30d-57214ee3afc6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "N_GENERATIONS = 10  #\n",
    "\n",
    "print(f\"Generating {N_GENERATIONS} QA couples...\")\n",
    "\n",
    "outputs = []\n",
    "for sampled_context in tqdm(random.sample(docs_processed, N_GENERATIONS)):\n",
    "    # Generate QA couple\n",
    "    output_QA_couple = call_llm(\n",
    "        llm_client, QA_generation_prompt.format(context=sampled_context.page_content)\n",
    "    )\n",
    "    try:\n",
    "        question = output_QA_couple.split(\"Factoid question: \")[-1].split(\"Answer: \")[0]\n",
    "        answer = output_QA_couple.split(\"Answer: \")[-1]\n",
    "        assert len(answer) < 300, \"Answer is too long\"\n",
    "        outputs.append(\n",
    "            {\n",
    "                \"context\": sampled_context.page_content,\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"source_doc\": sampled_context.metadata[\"source\"],\n",
    "            }\n",
    "        )\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a694f1",
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1768318003510,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "babMpkgPkdWg",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "45f11da0-7be4-4b9f-ea57-04464e6d928a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(pd.DataFrame(outputs).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5c291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:21:51.556749Z",
     "iopub.status.busy": "2026-01-21T07:21:51.556411Z",
     "iopub.status.idle": "2026-01-21T07:21:51.562506Z",
     "shell.execute_reply": "2026-01-21T07:21:51.561748Z",
     "shell.execute_reply.started": "2026-01-21T07:21:51.556722Z"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1768355996865,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "VQzMdsKvlqxh",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_groundedness_critique_prompt = \"\"\"\n",
    "You will be given a context and a question.\n",
    "Your task is to provide a 'total rating' scoring how well one can answer the given question unambiguously with the given context.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question is not answerable at all given the context, and 5 means that the question is clearly and unambiguously answerable with the context.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here are the question and context.\n",
    "\n",
    "Question: {question}\\n\n",
    "Context: {context}\\n\n",
    "Answer::: \"\"\"\n",
    "\n",
    "question_relevance_critique_prompt = \"\"\"\n",
    "You will be given a question.\n",
    "Your task is to provide a 'total rating' representing how useful this question can be to machine learning developers building NLP applications with the Hugging Face ecosystem.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question is not useful at all, and 5 means that the question is extremely useful.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here is the question.\n",
    "\n",
    "Question: {question}\\n\n",
    "Answer::: \"\"\"\n",
    "\n",
    "question_standalone_critique_prompt = \"\"\"\n",
    "You will be given a question.\n",
    "Your task is to provide a 'total rating' representing how context-independent this question is.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question depends on additional information to be understood, and 5 means that the question makes sense by itself.\n",
    "For instance, if the question refers to a particular setting, like 'in the context' or 'in the document', the rating must be 1.\n",
    "The questions can contain obscure technical nouns or acronyms like Gradio, Hub, Hugging Face or Space and still be a 5: it must simply be clear to an operator with access to documentation what the question is about.\n",
    "\n",
    "For instance, \"What is the name of the checkpoint from which the ViT model is imported?\" should receive a 1, since there is an implicit mention of a context, thus the question is not independent from the context.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here is the question.\n",
    "\n",
    "Question: {question}\\n\n",
    "Answer::: \"\"\"\n",
    "\n",
    "print(\"Running successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969be20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:21:55.696711Z",
     "iopub.status.busy": "2026-01-21T07:21:55.696384Z",
     "iopub.status.idle": "2026-01-21T07:24:16.525325Z",
     "shell.execute_reply": "2026-01-21T07:24:16.524568Z",
     "shell.execute_reply.started": "2026-01-21T07:21:55.696674Z"
    },
    "executionInfo": {
     "elapsed": 105987,
     "status": "ok",
     "timestamp": 1768356102866,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "Ap6_AWB4ls_3",
    "outputId": "d135fa34-3721-42d0-fff5-c8d6aab587cf",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Generating critique for each QA couple...\")\n",
    "for output in tqdm(outputs):\n",
    "    evaluations = {\n",
    "        \"groundedness\": call_llm(\n",
    "            llm_client,\n",
    "            question_groundedness_critique_prompt.format(\n",
    "                context=output[\"context\"], question=output[\"question\"]\n",
    "            ),\n",
    "        ),\n",
    "        \"relevance\": call_llm(\n",
    "            llm_client,\n",
    "            question_relevance_critique_prompt.format(question=output[\"question\"]),\n",
    "        ),\n",
    "        \"standalone\": call_llm(\n",
    "            llm_client,\n",
    "            question_standalone_critique_prompt.format(question=output[\"question\"]),\n",
    "        ),\n",
    "    }\n",
    "    try:\n",
    "        for criterion, evaluation in evaluations.items():\n",
    "            score, eval = (\n",
    "                int(evaluation.split(\"Total rating: \")[-1].strip()),\n",
    "                evaluation.split(\"Total rating: \")[-2].split(\"Evaluation: \")[1],\n",
    "            )\n",
    "            output.update(\n",
    "                {\n",
    "                    f\"{criterion}_score\": score,\n",
    "                    f\"{criterion}_eval\": eval,\n",
    "                }\n",
    "            )\n",
    "    except Exception as e:\n",
    "        continue\n",
    "display(pd.DataFrame(outputs).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f2e710",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-17T14:30:50.167675Z",
     "iopub.status.busy": "2026-01-17T14:30:50.166927Z",
     "iopub.status.idle": "2026-01-17T14:30:50.178495Z",
     "shell.execute_reply": "2026-01-17T14:30:50.177828Z",
     "shell.execute_reply.started": "2026-01-17T14:30:50.167641Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(pd.DataFrame(outputs).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35c2da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:24:35.922681Z",
     "iopub.status.busy": "2026-01-21T07:24:35.922380Z",
     "iopub.status.idle": "2026-01-21T07:24:35.982792Z",
     "shell.execute_reply": "2026-01-21T07:24:35.981972Z",
     "shell.execute_reply.started": "2026-01-21T07:24:35.922655Z"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1768356297010,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "Mc0tSR5Fm5zd",
    "outputId": "bc15a0be-9977-4c42-dbc4-c7192c63f376",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "generated_questions = pd.DataFrame.from_dict(outputs)\n",
    "\n",
    "print(\"Evaluation dataset before filtering:\")\n",
    "display(\n",
    "    generated_questions[\n",
    "        [\n",
    "            \"question\",\n",
    "            \"answer\",\n",
    "            \"groundedness_score\",\n",
    "            \"relevance_score\",\n",
    "            \"standalone_score\",\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "generated_questions = generated_questions.loc[\n",
    "    (generated_questions[\"groundedness_score\"] >= 4)\n",
    "    & (generated_questions[\"relevance_score\"] >= 4)\n",
    "    & (generated_questions[\"standalone_score\"] >= 4)\n",
    "]\n",
    "print(\"============================================\")\n",
    "print(\"Final evaluation dataset:\")\n",
    "display(\n",
    "    generated_questions[\n",
    "        [\n",
    "            \"question\",\n",
    "            \"answer\",\n",
    "            \"groundedness_score\",\n",
    "            \"relevance_score\",\n",
    "            \"standalone_score\",\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "eval_dataset = datasets.Dataset.from_pandas(\n",
    "    generated_questions, split=\"train\", preserve_index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd60520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:24:42.300393Z",
     "iopub.status.busy": "2026-01-21T07:24:42.299272Z",
     "iopub.status.idle": "2026-01-21T07:24:44.369880Z",
     "shell.execute_reply": "2026-01-21T07:24:44.369139Z",
     "shell.execute_reply.started": "2026-01-21T07:24:42.300351Z"
    },
    "executionInfo": {
     "elapsed": 4953,
     "status": "ok",
     "timestamp": 1768356306689,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "pJxGMnb2tpS9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_dataset = datasets.load_dataset(\"m-ric/huggingface_doc_qa_eval\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072eef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:24:44.489154Z",
     "iopub.status.busy": "2026-01-21T07:24:44.488378Z",
     "iopub.status.idle": "2026-01-21T07:24:44.658661Z",
     "shell.execute_reply": "2026-01-21T07:24:44.657879Z",
     "shell.execute_reply.started": "2026-01-21T07:24:44.489115Z"
    },
    "executionInfo": {
     "elapsed": 466,
     "status": "ok",
     "timestamp": 1768356307171,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "aq56DIaUtx5k",
    "outputId": "9ae154ac-968c-481d-f90f-15e56a2db7c0",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document as LangchainDocument\n",
    "\n",
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
    "    for doc in tqdm(ds)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c3148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:24:51.549773Z",
     "iopub.status.busy": "2026-01-21T07:24:51.549478Z",
     "iopub.status.idle": "2026-01-21T07:24:58.039644Z",
     "shell.execute_reply": "2026-01-21T07:24:58.039005Z",
     "shell.execute_reply.started": "2026-01-21T07:24:51.549748Z"
    },
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1768356309234,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "9zaxBmN3tz2A",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def split_documents(\n",
    "    chunk_size: int,\n",
    "    knowledge_base: List[LangchainDocument],\n",
    "    tokenizer_name: str,\n",
    ") -> List[LangchainDocument]:\n",
    "    \"\"\"\n",
    "    Split documents into chunks of size `chunk_size` characters and return a list of documents.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        AutoTokenizer.from_pretrained(tokenizer_name),\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=int(chunk_size / 10),\n",
    "        add_start_index=True,\n",
    "        strip_whitespace=True,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "    )\n",
    "\n",
    "    docs_processed = []\n",
    "    for doc in knowledge_base:\n",
    "        docs_processed += text_splitter.split_documents([doc])\n",
    "\n",
    "    # Remove duplicates\n",
    "    unique_texts = {}\n",
    "    docs_processed_unique = []\n",
    "    for doc in docs_processed:\n",
    "        if doc.page_content not in unique_texts:\n",
    "            unique_texts[doc.page_content] = True\n",
    "            docs_processed_unique.append(doc)\n",
    "\n",
    "    return docs_processed_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35fbf33",
   "metadata": {
    "id": "so1SxsiR8_IA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Retriever - embeddings** üóÇÔ∏è - The retriever acts like an internal search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99452a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:25:11.476363Z",
     "iopub.status.busy": "2026-01-21T07:25:11.475753Z",
     "iopub.status.idle": "2026-01-21T07:25:11.483624Z",
     "shell.execute_reply": "2026-01-21T07:25:11.482810Z",
     "shell.execute_reply.started": "2026-01-21T07:25:11.476334Z"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1768356311419,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "UAkt4Cv_t7eU",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "import os\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "\n",
    "def load_embeddings(\n",
    "    langchain_docs: List[LangchainDocument],\n",
    "    chunk_size: int,\n",
    "    embedding_model_name: Optional[str] = \"thenlper/gte-small\",\n",
    ") -> FAISS:\n",
    "    \"\"\"\n",
    "    Creates a FAISS index from the given embedding model and documents. Loads the index directly if it already exists.\n",
    "\n",
    "    Args:\n",
    "        langchain_docs: list of documents\n",
    "        chunk_size: size of the chunks to split the documents into\n",
    "        embedding_model_name: name of the embedding model to use\n",
    "\n",
    "    Returns:\n",
    "        FAISS index\n",
    "    \"\"\"\n",
    "    # load embedding_model\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=embedding_model_name,\n",
    "        multi_process=True,\n",
    "        model_kwargs={\"device\": \"cuda\"},\n",
    "        encode_kwargs={\n",
    "            \"normalize_embeddings\": True\n",
    "        },  # set True to compute cosine similarity\n",
    "    )\n",
    "\n",
    "    # Check if embeddings already exist on disk\n",
    "    index_name = (\n",
    "        f\"index_chunk:{chunk_size}_embeddings:{embedding_model_name.replace('/', '~')}\"\n",
    "    )\n",
    "    index_folder_path = f\"./data/indexes/{index_name}/\"\n",
    "    if os.path.isdir(index_folder_path):\n",
    "        return FAISS.load_local(\n",
    "            index_folder_path,\n",
    "            embedding_model,\n",
    "            distance_strategy=DistanceStrategy.COSINE,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(\"Index not found, generating it...\")\n",
    "        docs_processed = split_documents(\n",
    "            chunk_size,\n",
    "            langchain_docs,\n",
    "            embedding_model_name,\n",
    "        )\n",
    "        knowledge_index = FAISS.from_documents(\n",
    "            docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
    "        )\n",
    "        knowledge_index.save_local(index_folder_path)\n",
    "        return knowledge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a861ee2",
   "metadata": {
    "id": "lzHK7z85847b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "** the LLM Reader reads the retrieved documents to formulate its answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae46620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:28:47.909800Z",
     "iopub.status.busy": "2026-01-21T07:28:47.909045Z",
     "iopub.status.idle": "2026-01-21T07:28:47.913666Z",
     "shell.execute_reply": "2026-01-21T07:28:47.912919Z",
     "shell.execute_reply.started": "2026-01-21T07:28:47.909769Z"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1768356315129,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "l94v71gI75Rx",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAG_PROMPT_TEMPLATE = \"\"\"\n",
    "<|system|>\n",
    "Using the information contained in the context,\n",
    "give a comprehensive answer to the question directly and factually.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Provide the number of the source document when relevant.\n",
    "If the answer cannot be deduced from the context, do not give an answer.\n",
    "---\n",
    "### EXAMPLES OF EXPECTED BEHAVIOR\n",
    "\n",
    "Example 1 (Sufficient Information):\n",
    "Context: [1] The project was launched in 2021. [2] It cost $5 million to complete.\n",
    "Question: When did the project start and what was the budget?\n",
    "Assistant: The project launched in 2021 [1] and had a budget of $5 million [2].\n",
    "\n",
    "Example 2 (Insufficient Information):\n",
    "Context: [1] The company sells apples and oranges.\n",
    "Question: How much do the bananas cost?\n",
    "Assistant: I'm sorry, but the provided documents do not contain enough information to answer this question.\n",
    "\n",
    "---\n",
    "</s>\n",
    "<|user|>\n",
    "Context:\n",
    "{context}\n",
    "---\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f86978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T16:45:55.869005Z",
     "iopub.status.busy": "2026-01-14T16:45:55.868638Z",
     "iopub.status.idle": "2026-01-14T16:45:56.016376Z",
     "shell.execute_reply": "2026-01-14T16:45:56.014963Z",
     "shell.execute_reply.started": "2026-01-14T16:45:55.868972Z"
    },
    "executionInfo": {
     "elapsed": 116,
     "status": "ok",
     "timestamp": 1768356628365,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "oLP_OJGmQ9Sp",
    "outputId": "1e86414c-1803-4b0b-da7b-4c37fd28ba58",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2917f267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T16:46:33.295325Z",
     "iopub.status.busy": "2026-01-14T16:46:33.294803Z",
     "iopub.status.idle": "2026-01-14T16:46:33.349540Z",
     "shell.execute_reply": "2026-01-14T16:46:33.348362Z",
     "shell.execute_reply.started": "2026-01-14T16:46:33.295275Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        if filename == \".env\":\n",
    "            print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef359cb",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-14T16:49:56.503531Z",
     "iopub.status.busy": "2026-01-14T16:49:56.502635Z",
     "iopub.status.idle": "2026-01-14T16:50:02.706699Z",
     "shell.execute_reply": "2026-01-14T16:50:02.705441Z",
     "shell.execute_reply.started": "2026-01-14T16:49:56.503490Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8967ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:28:52.305366Z",
     "iopub.status.busy": "2026-01-21T07:28:52.304644Z",
     "iopub.status.idle": "2026-01-21T07:28:52.466891Z",
     "shell.execute_reply": "2026-01-21T07:28:52.466287Z",
     "shell.execute_reply.started": "2026-01-21T07:28:52.305331Z"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "error",
     "timestamp": 1768356668578,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "4QopU1md77s8",
    "outputId": "0d422289-1fee-44e9-b88c-19ae61094ea9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Try multiple .env locations\n",
    "env_paths = [\n",
    "    \"/kaggle/input/env-setup/.env\",\n",
    "    \".env\",\n",
    "    str(Path.home() / \".env\")\n",
    "]\n",
    "\n",
    "for env_path in env_paths:\n",
    "    if os.path.exists(env_path):\n",
    "        load_dotenv(dotenv_path=env_path)\n",
    "        break\n",
    "\n",
    "repo_id = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "READER_MODEL_NAME = \"zephyr-7b-beta\"\n",
    "HF_API_TOKEN = os.getenv(\"HF_API_TOKEN\")\n",
    "if not HF_API_TOKEN:\n",
    "    raise ValueError(\"HF_API_TOKEN is missing. Put it in your .env file!\")\n",
    "\n",
    "# Use HuggingFaceEndpoint instead of HuggingFaceHub\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    huggingfacehub_api_token=HF_API_TOKEN,\n",
    "    task=\"conversational\",\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.5,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "READER_LLM = ChatHuggingFace(llm=llm)\n",
    "print(\"Model initialized with HuggingFaceEndpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8e8fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T17:41:35.165578Z",
     "iopub.status.busy": "2026-01-14T17:41:35.165193Z",
     "iopub.status.idle": "2026-01-14T17:41:35.324047Z",
     "shell.execute_reply": "2026-01-14T17:41:35.323217Z",
     "shell.execute_reply.started": "2026-01-14T17:41:35.165533Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ragatouille<=0.0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218952e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T02:44:07.357579Z",
     "iopub.status.busy": "2026-01-15T02:44:07.356566Z",
     "iopub.status.idle": "2026-01-15T02:44:07.360949Z",
     "shell.execute_reply": "2026-01-15T02:44:07.360291Z",
     "shell.execute_reply.started": "2026-01-15T02:44:07.357545Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5cbc22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:28:58.808028Z",
     "iopub.status.busy": "2026-01-21T07:28:58.807309Z",
     "iopub.status.idle": "2026-01-21T07:29:32.304376Z",
     "shell.execute_reply": "2026-01-21T07:29:32.303378Z",
     "shell.execute_reply.started": "2026-01-21T07:28:58.807999Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1768354917722,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "elzBSSgG78PV",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from typing import Tuple\n",
    "\n",
    "def answer_with_rag(\n",
    "    question: str,\n",
    "    llm: LLM,\n",
    "    knowledge_index: VectorStore,\n",
    "    reranker: Optional[RAGPretrainedModel] = None,\n",
    "    num_retrieved_docs: int = 30,\n",
    "    num_docs_final: int = 7,\n",
    ") -> Tuple[str, List[LangchainDocument]]:\n",
    "    \"\"\"Answer a question using RAG with the given knowledge index.\"\"\"\n",
    "    # Gather documents with retriever\n",
    "    relevant_docs = knowledge_index.similarity_search(\n",
    "        query=question, k=num_retrieved_docs\n",
    "    )\n",
    "    relevant_docs = [doc.page_content for doc in relevant_docs]  # keep only the text\n",
    "\n",
    "    # Optionally rerank results\n",
    "    if reranker:\n",
    "        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n",
    "        relevant_docs = [doc[\"content\"] for doc in relevant_docs]\n",
    "\n",
    "    relevant_docs = relevant_docs[:num_docs_final]\n",
    "\n",
    "    # Build the final prompt\n",
    "    context = \"\\nExtracted documents:\\n\"\n",
    "    context += \"\".join(\n",
    "        [f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs)]\n",
    "    )\n",
    "\n",
    "    final_prompt = RAG_PROMPT_TEMPLATE.format(question=question, context=context)\n",
    "\n",
    "    # Redact an answer\n",
    "    #answer = llm(final_prompt)\n",
    "    #using ChatHuggingFace, we invoke it\n",
    "    response = llm.invoke(final_prompt)\n",
    "    answer = response.content\n",
    "\n",
    "    return answer, relevant_docs\n",
    "    \n",
    "print(\"Run sucessfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5d434",
   "metadata": {
    "id": "MNLDf5R-8w2A",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**setup a judge agent. ‚öñÔ∏èü§ñ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eea508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:29:32.306777Z",
     "iopub.status.busy": "2026-01-21T07:29:32.305950Z",
     "iopub.status.idle": "2026-01-21T07:29:32.319260Z",
     "shell.execute_reply": "2026-01-21T07:29:32.316531Z",
     "shell.execute_reply.started": "2026-01-21T07:29:32.306741Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1768354925337,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "WBM5kU4q79zh",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.language_models import BaseChatModel\n",
    "\n",
    "def run_rag_tests(\n",
    "    eval_dataset: datasets.Dataset,\n",
    "    llm,\n",
    "    knowledge_index: VectorStore,\n",
    "    output_file: str,\n",
    "    reranker: Optional[RAGPretrainedModel] = None,\n",
    "    verbose: Optional[bool] = True,\n",
    "    test_settings: Optional[str] = None,  # To document the test settings used\n",
    "):\n",
    "    \"\"\"Runs RAG tests on the given dataset and saves the results to the given output file.\"\"\"\n",
    "    try:  # load previous generations if they exist\n",
    "        with open(output_file, \"r\") as f:\n",
    "            outputs = json.load(f)\n",
    "    except:\n",
    "        outputs = []\n",
    "\n",
    "    for example in tqdm(eval_dataset):\n",
    "        question = example[\"question\"]\n",
    "        if question in [output[\"question\"] for output in outputs]:\n",
    "            continue\n",
    "\n",
    "        answer, relevant_docs = answer_with_rag(\n",
    "            question, llm, knowledge_index, reranker=reranker\n",
    "        )\n",
    "        if verbose:\n",
    "            print(\"=======================================================\")\n",
    "            print(f\"Question: {question}\")\n",
    "            print(f\"Answer: {answer}\")\n",
    "            print(f'True answer: {example[\"answer\"]}')\n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"true_answer\": example[\"answer\"],\n",
    "            \"source_doc\": example[\"source_doc\"],\n",
    "            \"generated_answer\": answer,\n",
    "            \"retrieved_docs\": [doc for doc in relevant_docs],\n",
    "        }\n",
    "        if test_settings:\n",
    "            result[\"test_settings\"] = test_settings\n",
    "        outputs.append(result)\n",
    "\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555d324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:29:32.394875Z",
     "iopub.status.busy": "2026-01-21T07:29:32.394634Z",
     "iopub.status.idle": "2026-01-21T07:29:32.399484Z",
     "shell.execute_reply": "2026-01-21T07:29:32.398808Z",
     "shell.execute_reply.started": "2026-01-21T07:29:32.394852Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1768354929601,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "i3YQ1zl_8BUs",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EVALUATION_PROMPT = \"\"\"###Task Description:\n",
    "An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n",
    "1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n",
    "2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n",
    "3. The output format should look as follows: \\\"Feedback: {{write a feedback for criteria}} [RESULT] {{an integer number between 1 and 5}}\\\"\n",
    "4. Please do not generate any other opening, closing, and explanations. Be sure to include [RESULT] in your output.\n",
    "\n",
    "###The instruction to evaluate:\n",
    "{instruction}\n",
    "\n",
    "###Response to evaluate:\n",
    "{response}\n",
    "\n",
    "###Reference Answer (Score 5):\n",
    "{reference_answer}\n",
    "\n",
    "###Score Rubrics:\n",
    "[Is the response correct, accurate, and factual based on the reference answer?]\n",
    "Score 1: The response is completely incorrect, inaccurate, and/or not factual.\n",
    "Score 2: The response is mostly incorrect, inaccurate, and/or not factual.\n",
    "Score 3: The response is somewhat correct, accurate, and/or factual.\n",
    "Score 4: The response is mostly correct, accurate, and factual.\n",
    "Score 5: The response is completely correct, accurate, and factual.\n",
    "\n",
    "###Feedback:\"\"\"\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "\n",
    "evaluation_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a fair evaluator language model.\"),\n",
    "        HumanMessagePromptTemplate.from_template(EVALUATION_PROMPT),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb54439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:29:37.753958Z",
     "iopub.status.busy": "2026-01-21T07:29:37.753258Z",
     "iopub.status.idle": "2026-01-21T07:29:37.913196Z",
     "shell.execute_reply": "2026-01-21T07:29:37.912517Z",
     "shell.execute_reply.started": "2026-01-21T07:29:37.753928Z"
    },
    "executionInfo": {
     "elapsed": 13836,
     "status": "error",
     "timestamp": 1768355478665,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "J8F_Gsx68BjF",
    "outputId": "be2ad9e9-da2a-424c-bd94-e44a1426f986",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import SystemMessage\n",
    "# from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "# from langchain_core.messages import SystemMessage\n",
    "#from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "import re\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "HF_TOKEN = os.environ[\"HF_API_TOKEN\"]\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = HF_TOKEN\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://router.huggingface.co/v1\"\n",
    "\n",
    "eval_chat_model = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    huggingfacehub_api_token=HF_TOKEN,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"do_sample\": False\n",
    "    }\n",
    ")\n",
    "\n",
    "evaluator_name = \"Mistral-7B\"\n",
    "\n",
    "evaluation_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a fair evaluator language model.\"),\n",
    "        HumanMessagePromptTemplate.from_template(EVALUATION_PROMPT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def evaluate_answers(\n",
    "    answer_path: str,\n",
    "    eval_chat_model,\n",
    "    evaluator_name: str,\n",
    "    evaluation_prompt_template: ChatPromptTemplate,\n",
    ") -> None:\n",
    "    \"\"\"Evaluates generated answers. Modifies the given answer file in place.\"\"\"\n",
    "    answers = []\n",
    "    if os.path.isfile(answer_path): \n",
    "        with open(answer_path, \"r\") as f:\n",
    "            answers = json.load(f)\n",
    "\n",
    "    print(f\"Starting evaluation with {evaluator_name}...\")\n",
    "\n",
    "    # We use enumerate to ensure we can save progress safely\n",
    "    for i, experiment in tqdm(enumerate(answers), total=len(answers)):\n",
    "        # Skip if already evaluated by this specific evaluator\n",
    "        if f\"eval_score_{evaluator_name}\" in experiment:\n",
    "            continue\n",
    "\n",
    "        eval_prompt = evaluation_prompt_template.format_messages(\n",
    "            instruction=experiment[\"question\"],\n",
    "            response=experiment[\"generated_answer\"],\n",
    "            reference_answer=experiment[\"true_answer\"],\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # Invoke the Llama model via HF\n",
    "            eval_result = eval_chat_model.invoke(eval_prompt)\n",
    "            content = eval_result.content\n",
    "            \n",
    "            # --- 2. ROBUST PARSING LOGIC ---\n",
    "            if \"[RESULT]\" in content:\n",
    "                #feedback, score = [item.strip() for item in content.split(\"[RESULT]\")]\n",
    "                match = re.search(r\"RESULTRESULT\\s*(\\d+)\", content)\n",
    "                score = match.group(1) if match else \"ERROR\"\n",
    "            else:\n",
    "                # Fallback: Assume the whole output is feedback, score is missing/error\n",
    "                feedback = content\n",
    "                score = \"ERROR_PARSING\"\n",
    "                logging.warning(f\"Missing [RESULT] at item {i}\")\n",
    "\n",
    "            experiment[f\"eval_score_{evaluator_name}\"] = score\n",
    "            experiment[f\"eval_feedback_{evaluator_name}\"] = feedback\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error item {i}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        with open(answer_path, \"w\") as f:\n",
    "            json.dump(answers, f, indent=4) # indent=4 makes it readable\n",
    "            \n",
    "print(\"Run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a1d93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T07:29:56.320408Z",
     "iopub.status.busy": "2026-01-21T07:29:56.319674Z",
     "iopub.status.idle": "2026-01-21T07:29:56.328095Z",
     "shell.execute_reply": "2026-01-21T07:29:56.327470Z",
     "shell.execute_reply.started": "2026-01-21T07:29:56.320378Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Replace this section:\n",
    "# eval_chat_model = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "# evaluator_name = \"GPT4\"\n",
    "\n",
    "# With this:\n",
    "evaluator_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "eval_client = InferenceClient(model=evaluator_model_id, timeout=120)\n",
    "evaluator_name = \"Mistral\"\n",
    "\n",
    "def evaluate_answers(\n",
    "    answer_path: str,\n",
    "    eval_client: InferenceClient,\n",
    "    evaluator_name: str,\n",
    "    evaluation_prompt_template: ChatPromptTemplate,\n",
    ") -> None:\n",
    "    \"\"\"Evaluates generated answers. Modifies the given answer file in place for better checkpointing.\"\"\"\n",
    "    answers = []\n",
    "    if os.path.isfile(answer_path):\n",
    "        answers = json.load(open(answer_path, \"r\"))\n",
    "\n",
    "    for experiment in tqdm(answers):\n",
    "        if f\"eval_score_{evaluator_name}\" in experiment:\n",
    "            continue\n",
    "\n",
    "        eval_prompt = EVALUATION_PROMPT.format(\n",
    "            instruction=experiment[\"question\"],\n",
    "            response=experiment[\"generated_answer\"],\n",
    "            reference_answer=experiment[\"true_answer\"],\n",
    "        )\n",
    "        \n",
    "        eval_result = call_llm(eval_client, eval_prompt)\n",
    "        \n",
    "        try:\n",
    "            # Try to split by [RESULT]\n",
    "            if \"[RESULT]\" in eval_result:\n",
    "                parts = eval_result.split(\"[RESULT]\")\n",
    "                feedback = parts[0].replace(\"Feedback:\", \"\").strip()\n",
    "                score_text = parts[1].strip()\n",
    "            else:\n",
    "                # Fallback: try to extract score from anywhere in the text\n",
    "                feedback = eval_result\n",
    "                score_text = eval_result\n",
    "            \n",
    "            # Extract just the number from score_text\n",
    "            import re\n",
    "            score_match = re.search(r'\\b([1-5])\\b', score_text)\n",
    "            if score_match:\n",
    "                score = score_match.group(1)\n",
    "            else:\n",
    "                score = \"1\"\n",
    "            \n",
    "            experiment[f\"eval_score_{evaluator_name}\"] = score\n",
    "            experiment[f\"eval_feedback_{evaluator_name}\"] = feedback\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing evaluation for question: {experiment['question'][:50]}...\")\n",
    "            print(f\"Raw response: {eval_result[:200]}...\")\n",
    "            experiment[f\"eval_score_{evaluator_name}\"] = \"1\"\n",
    "            experiment[f\"eval_feedback_{evaluator_name}\"] = f\"Error: {str(e)}\"\n",
    "\n",
    "        with open(answer_path, \"w\") as f:\n",
    "            json.dump(answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d8e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:12:03.294583Z",
     "iopub.status.busy": "2026-01-15T06:12:03.293933Z",
     "iopub.status.idle": "2026-01-15T06:12:07.301170Z",
     "shell.execute_reply": "2026-01-15T06:12:07.300592Z",
     "shell.execute_reply.started": "2026-01-15T06:12:03.294548Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6ebe424",
   "metadata": {
    "id": "s-Xybgjs8mGH",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "the tests and evaluate answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83f88f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:53:15.493026Z",
     "iopub.status.busy": "2026-01-21T08:53:15.492459Z",
     "iopub.status.idle": "2026-01-21T08:54:53.414023Z",
     "shell.execute_reply": "2026-01-21T08:54:53.413123Z",
     "shell.execute_reply.started": "2026-01-21T08:53:15.492995Z"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "error",
     "timestamp": 1768354454926,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "E6JepcQm8IS5",
    "outputId": "2f2dc9c6-cfee-468b-a1e3-9f89a225078a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./output\"):\n",
    "    os.mkdir(\"./output\")\n",
    "\n",
    "for chunk_size in [200]:  # Add other chunk sizes (in tokens) as needed\n",
    "    for embeddings in [\"thenlper/gte-small\"]:  # Add other embeddings as needed\n",
    "        for rerank in [True, False]:\n",
    "            settings_name = f\"chunk:{chunk_size}_embeddings:{embeddings.replace('/', '~')}_rerank:{rerank}_reader-model:{READER_MODEL_NAME}\"\n",
    "            output_file_name = f\"./output/rag_{settings_name}.json\"\n",
    "\n",
    "            print(f\"Running evaluation for {settings_name}:\")\n",
    "\n",
    "            print(\"Loading knowledge base embeddings...\")\n",
    "            knowledge_index = load_embeddings(\n",
    "                RAW_KNOWLEDGE_BASE,\n",
    "                chunk_size=chunk_size,\n",
    "                embedding_model_name=embeddings,\n",
    "            )\n",
    "\n",
    "            print(\"Running RAG...\")\n",
    "            reranker = (\n",
    "                RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "                if rerank\n",
    "                else None\n",
    "            )\n",
    "            run_rag_tests(\n",
    "                eval_dataset=eval_dataset,\n",
    "                llm=READER_LLM,\n",
    "                knowledge_index=knowledge_index,\n",
    "                output_file=output_file_name,\n",
    "                reranker=reranker,\n",
    "                verbose=False,\n",
    "                test_settings=settings_name,\n",
    "            )\n",
    "\n",
    "            print(\"Running evaluation...\")\n",
    "            evaluate_answers(\n",
    "                output_file_name,\n",
    "                #eval_chat_model,\n",
    "                eval_client,\n",
    "                evaluator_name,\n",
    "                evaluation_prompt_template,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63287b8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:56:04.407399Z",
     "iopub.status.busy": "2026-01-21T08:56:04.406496Z",
     "iopub.status.idle": "2026-01-21T08:56:04.418793Z",
     "shell.execute_reply": "2026-01-21T08:56:04.418232Z",
     "shell.execute_reply.started": "2026-01-21T08:56:04.407366Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check what's in your JSON files\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "\n",
    "for file in glob.glob(\"./output/*.json\"):\n",
    "    print(f\"\\n{file}:\")\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        if len(data) > 0:\n",
    "            # Check first entry\n",
    "            first_entry = data[0]\n",
    "            print(f\"  - Total entries: {len(data)}\")\n",
    "            print(f\"  - Keys in first entry: {first_entry.keys()}\")\n",
    "            print(f\"  - Has eval_score_Mistral: {'eval_score_Mistral' in first_entry}\")\n",
    "            if 'eval_score_Mistral' in first_entry:\n",
    "                print(f\"  - First score value: {first_entry['eval_score_Mistral']}\")\n",
    "                print(f\"  - First feedback sample: {first_entry.get('eval_feedback_Mistral', 'N/A')[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d1131",
   "metadata": {
    "id": "3OwUSwgh8dmh",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Inspect results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d73b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:56:49.265491Z",
     "iopub.status.busy": "2026-01-21T08:56:49.265199Z",
     "iopub.status.idle": "2026-01-21T08:56:49.277449Z",
     "shell.execute_reply": "2026-01-21T08:56:49.276791Z",
     "shell.execute_reply.started": "2026-01-21T08:56:49.265465Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "\n",
    "# 1. First, check if evaluations exist\n",
    "for file in glob.glob(\"./output/*.json\"):\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        has_eval = any('eval_score_Mistral' in entry for entry in data)\n",
    "        print(f\"{file}: Has evaluations = {has_eval}, Total entries = {len(data)}\")\n",
    "\n",
    "# 4. Process scores\n",
    "def extract_score_robust(x):\n",
    "    if pd.isna(x):\n",
    "        return 1\n",
    "    if isinstance(x, (int, float)):\n",
    "        return int(x)\n",
    "    \n",
    "    x = str(x)\n",
    "    \n",
    "    patterns = [\n",
    "        r'Score[:\\s]+([1-5])',\n",
    "        r'Total rating[:\\s]+([1-5])',\n",
    "        r'RESULTRESULT\\s*([1-5])',\n",
    "        r'\\b([1-5])\\b'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, x, re.IGNORECASE)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab494b31",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-21T08:56:53.072213Z",
     "iopub.status.busy": "2026-01-21T08:56:53.071555Z",
     "iopub.status.idle": "2026-01-21T08:56:53.092293Z",
     "shell.execute_reply": "2026-01-21T08:56:53.091678Z",
     "shell.execute_reply.started": "2026-01-21T08:56:53.072184Z"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "aborted",
     "timestamp": 1768322680281,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "dhtoGOJ-8Kg1",
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "# SORT the file list to ensure deterministic order\n",
    "#for file in files = sorted(glob.glob(\"./output/*.json\"))\n",
    "for file in glob.glob(\"./output/*.json\"):\n",
    "    output = pd.DataFrame(json.load(open(file, \"r\")))\n",
    "    output[\"settings\"] = file\n",
    "    outputs.append(output)\n",
    "result = pd.concat(outputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c348b71",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75668d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:56:57.647680Z",
     "iopub.status.busy": "2026-01-21T08:56:57.646998Z",
     "iopub.status.idle": "2026-01-21T08:56:57.653043Z",
     "shell.execute_reply": "2026-01-21T08:56:57.652356Z",
     "shell.execute_reply.started": "2026-01-21T08:56:57.647648Z"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "aborted",
     "timestamp": 1768322680283,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "L7wGEvAt8LA3",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result[\"eval_score_Mistral\"] = result[\"eval_score_Mistral\"].apply(\n",
    "#     lambda x: int(x) if isinstance(x, str) else 1\n",
    "# )\n",
    "# result[\"eval_score_Mistral\"] = (result[\"eval_score_Mistral\"] - 1) / 4\n",
    "result[\"eval_score_Mistral\"] = result[\"eval_score_Mistral\"].apply(extract_score_robust)\n",
    "result[\"eval_score_Mistral\"] = (result[\"eval_score_Mistral\"] - 1) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11ace7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:57:02.065905Z",
     "iopub.status.busy": "2026-01-21T08:57:02.065177Z",
     "iopub.status.idle": "2026-01-21T08:57:02.072754Z",
     "shell.execute_reply": "2026-01-21T08:57:02.071912Z",
     "shell.execute_reply.started": "2026-01-21T08:57:02.065878Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Examine the actual data in result DataFrame\n",
    "print(\"Result DataFrame Info:\")\n",
    "print(result.columns)\n",
    "print(\"\\nFirst few rows of eval_score_Mistral:\")\n",
    "print(result[\"eval_score_Mistral\"].head(10))\n",
    "print(\"\\nValue counts:\")\n",
    "print(result[\"eval_score_Mistral\"].value_counts())\n",
    "print(\"\\nData types:\")\n",
    "print(result[\"eval_score_Mistral\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e793c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:57:05.475947Z",
     "iopub.status.busy": "2026-01-21T08:57:05.475262Z",
     "iopub.status.idle": "2026-01-21T08:57:05.481975Z",
     "shell.execute_reply": "2026-01-21T08:57:05.481104Z",
     "shell.execute_reply.started": "2026-01-21T08:57:05.475918Z"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "aborted",
     "timestamp": 1768322680286,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "MsoPJpDv8MXD",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate averages\n",
    "average_scores = result.groupby(\"settings\")[\"eval_score_Mistral\"].mean()\n",
    "print(average_scores.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbfdc14",
   "metadata": {
    "id": "mZDrwPNI8UEr",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Example results**\n",
    "Let us load the results that I obtained by tweaking the different options available in this notebook. For more detail on why these options could work or not, see the notebook on advanced_RAG.\n",
    "\n",
    "As you can see in the graph below, some tweaks do not bring any improvement, some give huge performance boosts.\n",
    "\n",
    "‚û°Ô∏è There is no single good recipe: you should try several different directions when tuning your RAG systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e297eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:57:08.918290Z",
     "iopub.status.busy": "2026-01-21T08:57:08.917956Z",
     "iopub.status.idle": "2026-01-21T08:57:12.160754Z",
     "shell.execute_reply": "2026-01-21T08:57:12.160222Z",
     "shell.execute_reply.started": "2026-01-21T08:57:08.918262Z"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "aborted",
     "timestamp": 1768322680288,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "pP4i0hwt8OBU",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "scores = datasets.load_dataset(\"m-ric/rag_scores_cookbook\", split=\"train\")\n",
    "scores = pd.Series(scores[\"score\"], index=scores[\"settings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbf919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:57:16.783770Z",
     "iopub.status.busy": "2026-01-21T08:57:16.783215Z",
     "iopub.status.idle": "2026-01-21T08:57:20.690862Z",
     "shell.execute_reply": "2026-01-21T08:57:20.690223Z",
     "shell.execute_reply.started": "2026-01-21T08:57:16.783740Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1768322680290,
     "user": {
      "displayName": "Ch∆∞∆°ng Cao",
      "userId": "13396380722713407632"
     },
     "user_tz": -420
    },
    "id": "1ax_zbx08QPE",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    scores,\n",
    "    color=scores,\n",
    "    labels={\n",
    "        \"value\": \"Accuracy\",\n",
    "        \"settings\": \"Configuration\",\n",
    "    },\n",
    "    color_continuous_scale=\"bluered\",\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    barmode=\"group\",\n",
    "    yaxis_range=[0, 100],\n",
    "    title=\"<b>Accuracy of different RAG configurations</b>\",\n",
    "    xaxis_title=\"RAG settings\",\n",
    "    font=dict(size=15),\n",
    ")\n",
    "fig.layout.yaxis.ticksuffix = \"%\"\n",
    "fig.update_coloraxes(showscale=False)\n",
    "fig.update_traces(texttemplate=\"%{y:.1f}\", textposition=\"outside\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da28cb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Faithfulness and relevant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d0b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:57:28.381929Z",
     "iopub.status.busy": "2026-01-21T08:57:28.381640Z",
     "iopub.status.idle": "2026-01-21T08:57:28.388083Z",
     "shell.execute_reply": "2026-01-21T08:57:28.387415Z",
     "shell.execute_reply.started": "2026-01-21T08:57:28.381905Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "from typing import List, Optional\n",
    "import json\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#  Structured Output Definition (Simplified - no Pydantic needed for your setup)\n",
    "def parse_eval_response(response_text: str) -> dict:\n",
    "    \"\"\"Extract reasoning and score from LLM response.\"\"\"\n",
    "    try:\n",
    "        # Try to find score pattern\n",
    "        score_match = re.search(r'\\b([0-5])\\b', response_text)\n",
    "        score = int(score_match.group(1)) / 5.0 if score_match else 0.0\n",
    "        \n",
    "        # Extract reasoning (everything before [RESULT] or the whole text)\n",
    "        if \"[RESULT]\" in response_text:\n",
    "            reasoning = response_text.split(\"[RESULT]\")[0].replace(\"Feedback:\", \"\").strip()\n",
    "        else:\n",
    "            reasoning = response_text[:200]  # First 200 chars as reasoning\n",
    "        \n",
    "        return {\"reasoning\": reasoning, \"score\": score}\n",
    "    except:\n",
    "        return {\"reasoning\": \"Parse error\", \"score\": 0.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b22935a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:57:42.851938Z",
     "iopub.status.busy": "2026-01-21T08:57:42.851604Z",
     "iopub.status.idle": "2026-01-21T08:57:42.856396Z",
     "shell.execute_reply": "2026-01-21T08:57:42.855722Z",
     "shell.execute_reply.started": "2026-01-21T08:57:42.851902Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# . Evaluation Prompts for Mistral \n",
    "FAITHFULNESS_PROMPT = \"\"\"You are an expert RAG evaluator. Evaluate whether the response is faithful to the context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Response to evaluate:\n",
    "{response}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Task: Determine if the response is derived ONLY from the given context. Do not use outside knowledge.\n",
    "\n",
    "Provide your evaluation in this format:\n",
    "Evaluation: (your detailed reasoning)\n",
    "Total rating: (a number between 1 and 5, where 1 = not faithful at all, 5 = completely faithful)\n",
    "\n",
    "[RESULT] (just the number 1-5)\"\"\"\n",
    "\n",
    "RELEVANCE_PROMPT = \"\"\"You are an expert RAG evaluator. Evaluate whether the response is relevant to the question.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Response to evaluate:\n",
    "{response}\n",
    "\n",
    "Task: Determine if the response directly and comprehensively answers the question.\n",
    "\n",
    "Provide your evaluation in this format:\n",
    "Evaluation: (your detailed reasoning)\n",
    "Total rating: (a number between 1 and 5, where 1 = not relevant at all, 5 = highly relevant)\n",
    "\n",
    "[RESULT] (just the number 1-5)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26d541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:57:45.948777Z",
     "iopub.status.busy": "2026-01-21T08:57:45.948220Z",
     "iopub.status.idle": "2026-01-21T08:57:45.957736Z",
     "shell.execute_reply": "2026-01-21T08:57:45.957005Z",
     "shell.execute_reply.started": "2026-01-21T08:57:45.948749Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_professional_eval(eval_results_path: str, eval_client, evaluator_name: str = \"Mistral\"):\n",
    "    \"\"\"\n",
    "    Run faithfulness and relevance evaluation on existing RAG results.\n",
    "    \n",
    "    Args:\n",
    "        eval_results_path: Path to JSON file with RAG results (from run_rag_tests)\n",
    "        eval_client: Your InferenceClient for evaluation\n",
    "        evaluator_name: Name of evaluator model\n",
    "    \"\"\"\n",
    "    # Load existing RAG results\n",
    "    with open(eval_results_path, 'r') as f:\n",
    "        rag_results = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    print(f\"Starting evaluation for {len(rag_results)} samples...\")\n",
    "    \n",
    "    for experiment in tqdm(rag_results):\n",
    "        # Skip if already evaluated\n",
    "        if f\"faithfulness_{evaluator_name}\" in experiment and f\"relevance_{evaluator_name}\" in experiment:\n",
    "            results.append({\n",
    "                \"Question\": experiment['question'][:50] + \"...\",\n",
    "                \"Faithfulness\": experiment[f\"faithfulness_{evaluator_name}\"],\n",
    "                \"Relevance\": experiment[f\"relevance_{evaluator_name}\"],\n",
    "                \"Generated_Answer\": experiment['generated_answer'][:100] + \"...\"\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Prepare context from retrieved docs\n",
    "        context = \"\\n\\n\".join([f\"Document {i}: {doc}\" for i, doc in enumerate(experiment['retrieved_docs'])])\n",
    "        \n",
    "        # Evaluate Faithfulness\n",
    "        faithfulness_prompt = FAITHFULNESS_PROMPT.format(\n",
    "            context=context,\n",
    "            response=experiment['generated_answer'],\n",
    "            question=experiment['question']\n",
    "        )\n",
    "        faithfulness_response = call_llm(eval_client, faithfulness_prompt)\n",
    "        faithfulness_result = parse_eval_response(faithfulness_response)\n",
    "        \n",
    "        # Evaluate Relevance\n",
    "        relevance_prompt = RELEVANCE_PROMPT.format(\n",
    "            question=experiment['question'],\n",
    "            response=experiment['generated_answer']\n",
    "        )\n",
    "        relevance_response = call_llm(eval_client, relevance_prompt)\n",
    "        relevance_result = parse_eval_response(relevance_response)\n",
    "        \n",
    "        # Store results\n",
    "        experiment[f\"faithfulness_score_{evaluator_name}\"] = faithfulness_result['score']\n",
    "        experiment[f\"faithfulness_reasoning_{evaluator_name}\"] = faithfulness_result['reasoning']\n",
    "        experiment[f\"relevance_score_{evaluator_name}\"] = relevance_result['score']\n",
    "        experiment[f\"relevance_reasoning_{evaluator_name}\"] = relevance_result['reasoning']\n",
    "        \n",
    "        results.append({\n",
    "            \"Question\": experiment['question'][:50] + \"...\",\n",
    "            \"Faithfulness\": faithfulness_result['score'],\n",
    "            \"Relevance\": relevance_result['score'],\n",
    "            \"Generated_Answer\": experiment['generated_answer'][:100] + \"...\"\n",
    "        })\n",
    "        \n",
    "        # Save incrementally\n",
    "        with open(eval_results_path, 'w') as f:\n",
    "            json.dump(rag_results, f, indent=2)\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48a1e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T08:57:49.637273Z",
     "iopub.status.busy": "2026-01-21T08:57:49.636667Z",
     "iopub.status.idle": "2026-01-21T08:57:49.642186Z",
     "shell.execute_reply": "2026-01-21T08:57:49.641512Z",
     "shell.execute_reply.started": "2026-01-21T08:57:49.637245Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Display Results with Styling\n",
    "def display_report(df):\n",
    "    \"\"\"Display evaluation results with conditional formatting.\"\"\"\n",
    "    if len(df) == 0:\n",
    "        print(\"No results to display\")\n",
    "        return None\n",
    "    \n",
    "    styled = df.style \\\n",
    "        .background_gradient(cmap='RdYlGn', subset=['Faithfulness', 'Relevance'], vmin=0, vmax=1) \\\n",
    "        .format({'Faithfulness': '{:.1%}', 'Relevance': '{:.1%}'}) \\\n",
    "        .set_caption(\"RAG Performance Analysis: Faithfulness vs. Relevance\") \\\n",
    "        .set_properties(**{'text-align': 'left'}) \\\n",
    "        .set_table_styles([\n",
    "            {'selector': 'th', 'props': [('font-size', '11pt'), ('background-color', '#f0f0f0')]},\n",
    "            {'selector': 'caption', 'props': [('font-size', '14pt'), ('font-weight', 'bold')]}\n",
    "        ])\n",
    "    \n",
    "    return styled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635ebe2",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-21T11:06:44.151379Z",
     "iopub.status.busy": "2026-01-21T11:06:44.151060Z",
     "iopub.status.idle": "2026-01-21T11:06:53.071205Z",
     "shell.execute_reply": "2026-01-21T11:06:53.070214Z",
     "shell.execute_reply.started": "2026-01-21T11:06:44.151352Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# . Summary Statistics\n",
    "def get_eval_summary(df):\n",
    "    \"\"\"Get summary statistics of evaluation metrics.\"\"\"\n",
    "    summary = {\n",
    "        'Avg Faithfulness': df['Faithfulness'].mean(),\n",
    "        'Avg Relevance': df['Relevance'].mean(),\n",
    "        'Min Faithfulness': df['Faithfulness'].min(),\n",
    "        'Max Faithfulness': df['Faithfulness'].max(),\n",
    "        'Min Relevance': df['Relevance'].min(),\n",
    "        'Max Relevance': df['Relevance'].max(),\n",
    "        'Total Samples': len(df)\n",
    "    }\n",
    "    return pd.Series(summary)\n",
    "\n",
    "# After running your RAG tests, evaluate them:\n",
    "for file in glob.glob(\"./output/*.json\"):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating: {file}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Run professional evaluation\n",
    "    results_df = run_professional_eval(file, eval_client, evaluator_name=\"Mistral\")\n",
    "    \n",
    "    # Display styled report\n",
    "    print(\"\\nDetailed Results:\")\n",
    "    display(display_report(results_df))\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(get_eval_summary(results_df))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75233b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T11:07:02.572539Z",
     "iopub.status.busy": "2026-01-21T11:07:02.572237Z",
     "iopub.status.idle": "2026-01-21T11:07:02.592589Z",
     "shell.execute_reply": "2026-01-21T11:07:02.591834Z",
     "shell.execute_reply.started": "2026-01-21T11:07:02.572513Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aggregate results across all settings\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AGGREGATE RESULTS ACROSS ALL CONFIGURATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_results = []\n",
    "for file in glob.glob(\"./output/*.json\"):\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    setting_name = file.replace('./output/rag_', '').replace('.json', '')\n",
    "    \n",
    "    faithfulness_scores = [d.get('faithfulness_score_Mistral', 0) for d in data if 'faithfulness_score_Mistral' in d]\n",
    "    relevance_scores = [d.get('relevance_score_Mistral', 0) for d in data if 'relevance_score_Mistral' in d]\n",
    "    \n",
    "    if faithfulness_scores and relevance_scores:\n",
    "        all_results.append({\n",
    "            'Setting': setting_name,\n",
    "            'Avg Faithfulness': sum(faithfulness_scores) / len(faithfulness_scores),\n",
    "            'Avg Relevance': sum(relevance_scores) / len(relevance_scores),\n",
    "            'Combined Score': (sum(faithfulness_scores) / len(faithfulness_scores) + sum(relevance_scores) / len(relevance_scores)) / 2\n",
    "        })\n",
    "\n",
    "aggregate_df = pd.DataFrame(all_results).sort_values('Combined Score', ascending=False)\n",
    "display(aggregate_df.style.background_gradient(cmap='RdYlGn', subset=['Avg Faithfulness', 'Avg Relevance', 'Combined Score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67546d3f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Metric table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38eb130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T11:07:08.130592Z",
     "iopub.status.busy": "2026-01-21T11:07:08.129848Z",
     "iopub.status.idle": "2026-01-21T11:07:08.843653Z",
     "shell.execute_reply": "2026-01-21T11:07:08.843073Z",
     "shell.execute_reply.started": "2026-01-21T11:07:08.130562Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============= CREATE COMPREHENSIVE ACCURACY METRICS TABLE =============\n",
    "\n",
    "def create_accuracy_metrics_table():\n",
    "    \"\"\"\n",
    "    Creates a comprehensive table showing all accuracy metrics across different RAG configurations.\n",
    "    \"\"\"\n",
    "    all_metrics = []\n",
    "    \n",
    "    for file in glob.glob(\"./output/*.json\"):\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Extract setting name\n",
    "        setting_name = file.replace('./output/rag_', '').replace('.json', '')\n",
    "        \n",
    "        # Parse setting components\n",
    "        parts = setting_name.split('_')\n",
    "        chunk_size = parts[0].replace('chunk:', '')\n",
    "        embeddings = parts[1].replace('embeddings:', '').replace('~', '/')\n",
    "        rerank = parts[2].replace('rerank:', '')\n",
    "        reader = parts[3].replace('reader-model:', '')\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'Configuration': setting_name,\n",
    "            'Chunk Size': chunk_size,\n",
    "            'Embeddings': embeddings,\n",
    "            'Reranking': rerank,\n",
    "            'Reader Model': reader,\n",
    "            'Total Samples': len(data)\n",
    "        }\n",
    "        \n",
    "        # Overall Accuracy (from eval_score_Mistral or eval_score_Mixtral or eval_score_GPT4)\n",
    "        for eval_name in ['Mistral', 'Mixtral', 'GPT4']:\n",
    "            scores = []\n",
    "            for d in data:\n",
    "                score_key = f'eval_score_{eval_name}'\n",
    "                if score_key in d:\n",
    "                    # Extract score\n",
    "                    score_val = d[score_key]\n",
    "                    if isinstance(score_val, str):\n",
    "                        # Try to extract number\n",
    "                        import re\n",
    "                        match = re.search(r'\\b([1-5])\\b', score_val)\n",
    "                        if match:\n",
    "                            scores.append(int(match.group(1)))\n",
    "                        else:\n",
    "                            scores.append(1)\n",
    "                    elif isinstance(score_val, (int, float)):\n",
    "                        scores.append(int(score_val))\n",
    "            \n",
    "            if scores:\n",
    "                # Normalize to 0-1 scale\n",
    "                normalized_scores = [(s - 1) / 4 for s in scores]\n",
    "                metrics[f'Overall Accuracy ({eval_name})'] = sum(normalized_scores) / len(normalized_scores)\n",
    "        \n",
    "        # Faithfulness Score\n",
    "        faithfulness_scores = []\n",
    "        for d in data:\n",
    "            for eval_name in ['Mistral', 'Mixtral']:\n",
    "                key = f'faithfulness_score_{eval_name}'\n",
    "                if key in d:\n",
    "                    faithfulness_scores.append(d[key])\n",
    "        \n",
    "        if faithfulness_scores:\n",
    "            metrics['Faithfulness'] = sum(faithfulness_scores) / len(faithfulness_scores)\n",
    "        \n",
    "        # Relevance Score\n",
    "        relevance_scores = []\n",
    "        for d in data:\n",
    "            for eval_name in ['Mistral', 'Mixtral']:\n",
    "                key = f'relevance_score_{eval_name}'\n",
    "                if key in d:\n",
    "                    relevance_scores.append(d[key])\n",
    "        \n",
    "        if relevance_scores:\n",
    "            metrics['Relevance'] = sum(relevance_scores) / len(relevance_scores)\n",
    "        \n",
    "        # Combined Score (if both faithfulness and relevance exist)\n",
    "        if 'Faithfulness' in metrics and 'Relevance' in metrics:\n",
    "            metrics['Combined Score'] = (metrics['Faithfulness'] + metrics['Relevance']) / 2\n",
    "        \n",
    "        all_metrics.append(metrics)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_metrics)\n",
    "    \n",
    "    # Sort by best overall performance\n",
    "    if 'Combined Score' in df.columns:\n",
    "        df = df.sort_values('Combined Score', ascending=False)\n",
    "    elif any('Overall Accuracy' in col for col in df.columns):\n",
    "        accuracy_col = [col for col in df.columns if 'Overall Accuracy' in col][0]\n",
    "        df = df.sort_values(accuracy_col, ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create the table\n",
    "metrics_table = create_accuracy_metrics_table()\n",
    "\n",
    "# Display with styling\n",
    "def style_metrics_table(df):\n",
    "    \"\"\"Apply professional styling to metrics table.\"\"\"\n",
    "    \n",
    "    # Identify numeric columns for formatting\n",
    "    numeric_cols = [col for col in df.columns if any(x in col for x in ['Accuracy', 'Faithfulness', 'Relevance', 'Score'])]\n",
    "    \n",
    "    # Create styled dataframe\n",
    "    styled = df.style\n",
    "    \n",
    "    # Apply gradient to numeric columns\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            styled = styled.background_gradient(cmap='RdYlGn', subset=[col], vmin=0, vmax=1)\n",
    "    \n",
    "    # Format percentages\n",
    "    format_dict = {col: '{:.2%}' for col in numeric_cols}\n",
    "    styled = styled.format(format_dict)\n",
    "    \n",
    "    # Highlight best scores\n",
    "    if numeric_cols:\n",
    "        styled = styled.highlight_max(subset=numeric_cols, color='lightgreen', axis=0)\n",
    "    \n",
    "    # Set table properties\n",
    "    styled = styled.set_caption(\"RAG System Performance Metrics - Comprehensive Evaluation\") \\\n",
    "        .set_properties(**{'text-align': 'center'}) \\\n",
    "        .set_table_styles([\n",
    "            {'selector': 'th', 'props': [('font-size', '12pt'), ('background-color', '#40466e'), ('color', 'white'), ('font-weight', 'bold')]},\n",
    "            {'selector': 'caption', 'props': [('font-size', '16pt'), ('font-weight', 'bold'), ('margin-bottom', '10px')]},\n",
    "            {'selector': 'td', 'props': [('font-size', '11pt')]},\n",
    "        ])\n",
    "    \n",
    "    return styled\n",
    "\n",
    "# Display the styled table\n",
    "print(\"=\"*100)\n",
    "print(\"COMPREHENSIVE RAG ACCURACY METRICS\")\n",
    "print(\"=\"*100)\n",
    "display(style_metrics_table(metrics_table))\n",
    "\n",
    "# ============= SUMMARY STATISTICS =============\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Get numeric columns only\n",
    "numeric_cols = metrics_table.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Calculate summary stats\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Metric': numeric_cols,\n",
    "    'Mean': [metrics_table[col].mean() for col in numeric_cols],\n",
    "    'Std Dev': [metrics_table[col].std() for col in numeric_cols],\n",
    "    'Min': [metrics_table[col].min() for col in numeric_cols],\n",
    "    'Max': [metrics_table[col].max() for col in numeric_cols],\n",
    "    'Range': [metrics_table[col].max() - metrics_table[col].min() for col in numeric_cols]\n",
    "})\n",
    "\n",
    "display(summary_stats.style.format({\n",
    "    'Mean': '{:.2%}',\n",
    "    'Std Dev': '{:.2%}',\n",
    "    'Min': '{:.2%}',\n",
    "    'Max': '{:.2%}',\n",
    "    'Range': '{:.2%}'\n",
    "}).background_gradient(cmap='Blues', subset=['Mean', 'Max']))\n",
    "\n",
    "# ============= CONFIGURATION COMPARISON =============\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"IMPACT OF DIFFERENT CONFIGURATIONS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Compare impact of reranking\n",
    "if 'Reranking' in metrics_table.columns and len(metrics_table) > 0:\n",
    "    rerank_comparison = metrics_table.groupby('Reranking')[numeric_cols].mean()\n",
    "    print(\"\\n Impact of Reranking:\")\n",
    "    display(rerank_comparison.style.format('{:.2%}').background_gradient(cmap='RdYlGn'))\n",
    "\n",
    "# Compare impact of chunk size\n",
    "if 'Chunk Size' in metrics_table.columns and len(metrics_table) > 0:\n",
    "    chunk_comparison = metrics_table.groupby('Chunk Size')[numeric_cols].mean()\n",
    "    print(\"\\n Impact of Chunk Size:\")\n",
    "    display(chunk_comparison.style.format('{:.2%}').background_gradient(cmap='RdYlGn'))\n",
    "\n",
    "# Compare impact of embeddings\n",
    "if 'Embeddings' in metrics_table.columns and len(metrics_table) > 0:\n",
    "    embedding_comparison = metrics_table.groupby('Embeddings')[numeric_cols].mean()\n",
    "    print(\"\\n Impact of Embedding Models:\")\n",
    "    display(embedding_comparison.style.format('{:.2%}').background_gradient(cmap='RdYlGn'))\n",
    "\n",
    "# Compare impact of reader models\n",
    "if 'Reader Model' in metrics_table.columns and len(metrics_table) > 0:\n",
    "    reader_comparison = metrics_table.groupby('Reader Model')[numeric_cols].mean()\n",
    "    print(\"\\n Impact of Reader Models:\")\n",
    "    display(reader_comparison.style.format('{:.2%}').background_gradient(cmap='RdYlGn'))\n",
    "\n",
    "# ============= BEST CONFIGURATION =============\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\" BEST PERFORMING CONFIGURATION\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if len(metrics_table) > 0:\n",
    "    # Determine best config based on available metrics\n",
    "    if 'Combined Score' in metrics_table.columns:\n",
    "        best_idx = metrics_table['Combined Score'].idxmax()\n",
    "        metric_name = 'Combined Score'\n",
    "    else:\n",
    "        accuracy_cols = [col for col in metrics_table.columns if 'Overall Accuracy' in col]\n",
    "        if accuracy_cols:\n",
    "            metric_name = accuracy_cols[0]\n",
    "            best_idx = metrics_table[metric_name].idxmax()\n",
    "        else:\n",
    "            best_idx = 0\n",
    "            metric_name = 'Unknown'\n",
    "    \n",
    "    best_config = metrics_table.loc[best_idx]\n",
    "    \n",
    "    print(f\"\\n Best Configuration (by {metric_name}):\")\n",
    "    print(f\"   Configuration: {best_config['Configuration']}\")\n",
    "    print(f\"   Chunk Size: {best_config['Chunk Size']}\")\n",
    "    print(f\"   Embeddings: {best_config['Embeddings']}\")\n",
    "    print(f\"   Reranking: {best_config['Reranking']}\")\n",
    "    print(f\"   Reader Model: {best_config['Reader Model']}\")\n",
    "    print()\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in best_config:\n",
    "            print(f\"   {col}: {best_config[col]:.2%}\")\n",
    "\n",
    "# ============= EXPORT OPTIONS =============\n",
    "\n",
    "# Export to CSV\n",
    "metrics_table.to_csv('./output/rag_accuracy_metrics.csv', index=False)\n",
    "print(\"\\n Full metrics table saved to: ./output/rag_accuracy_metrics.csv\")\n",
    "\n",
    "# Export to Excel with formatting (if openpyxl is available)\n",
    "try:\n",
    "    with pd.ExcelWriter('./output/rag_accuracy_metrics.xlsx', engine='openpyxl') as writer:\n",
    "        metrics_table.to_excel(writer, sheet_name='Metrics', index=False)\n",
    "        summary_stats.to_excel(writer, sheet_name='Summary', index=False)\n",
    "    print(\" Excel report saved to: ./output/rag_accuracy_metrics.xlsx\")\n",
    "except:\n",
    "    print(\"  Could not save Excel file (openpyxl might not be installed)\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP9fiKAZj89gO4AOvB72/+W",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9303861,
     "sourceId": 14565836,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 94.0078,
   "end_time": "2026-01-21T11:09:51.404945",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-21T11:08:17.397145",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "025791f3dafa4d2898ed219b0133726f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0bb595a1934147f9907fe6e8de8cd556": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0c7ba9bbd36d47d8bd1dd68a62eec7f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "Login",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_802bb49cac5042dfa0bbfeed5e3bc891",
       "style": "IPY_MODEL_72b68f977b514515bae5c6ef23fdb2e4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "111c197f21424d2b97670459b759f4a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d51a217ab03543a89c2566e1844ef8a1",
        "IPY_MODEL_4eef4c84103d45859daba4b9fc09dbed",
        "IPY_MODEL_dbc460d7eaf549b697061cee9d5a81ff"
       ],
       "layout": "IPY_MODEL_876a40e482d4442d94b8268a50e78002",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1a1b3ca616154088a32e870f3cffaf35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e96841e6807d4c528a630579936d5b99",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_264dc2c207d849928649434cb1456286",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá2647/2647‚Äá[00:00&lt;00:00,‚Äá24987.70it/s]"
      }
     },
     "1bf06ef371f54d1a95e999113a945edf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d81139b072544f0b9c14654755a77ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2290154d282745ee80914930e34e6ac7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "25e91fc16cbf488f99a811af4ffaa7c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_af1fb63fbf1e44fc818abe30b3950137",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_37553d2ef8bc41ffa5158461d4926f95",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "264dc2c207d849928649434cb1456286": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "26bc766c13fd4042ae866da719227613": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "PasswordModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "PasswordModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "PasswordView",
       "continuous_update": true,
       "description": "Token:",
       "description_allow_html": false,
       "disabled": false,
       "layout": "IPY_MODEL_ada6e0f671ec41ca84eb5420051e6625",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_5f9ca79074174b6589ce972182b965f9",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "2b912841397047a2ae1077343c7b9590": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "30e9f14fb9ce4bc2ad8d208f6b150ec0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c755d5412b5c4136811152c6f144382b",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_cb168b90804f4dce92fe8e20fd3e22c8",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá21.0/21.0‚Äá[00:00&lt;00:00,‚Äá1.48kB/s]"
      }
     },
     "33d6ab90aeb34130a61dcb8f24935227": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37553d2ef8bc41ffa5158461d4926f95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3ec55fa1d7574d8297e9f8b99e377856": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_894192aac2f044bb883b6b8c86bedb87",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_fe311916ec46425ebd8f64f4be71f561",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1/1‚Äá[00:00&lt;00:00,‚Äá175.96it/s]"
      }
     },
     "403266b8921a4369962d70a5e261f8ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "42c6db21af3c49b1b37609a15c4422f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a6611c557aba4d21b0275d908c4b9071",
       "max": 21.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_55e53dfb8e6f4441aa3b855415362d55",
       "tabbable": null,
       "tooltip": null,
       "value": 21.0
      }
     },
     "479929f998d844a7b1213c9251e0712f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "486e25d76dfe4c83bb55e087f89099b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4cd05581ab1640a8a2eabc82472f8708": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e142e755c1f43ab93acc81541c243bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4eef4c84103d45859daba4b9fc09dbed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca74af4920944e6481d85516570e5a03",
       "max": 2647.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2b912841397047a2ae1077343c7b9590",
       "tabbable": null,
       "tooltip": null,
       "value": 2647.0
      }
     },
     "51d3d2e2b1f9450086aed38ed6248824": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1d81139b072544f0b9c14654755a77ac",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_a478ccf3804d4b4fa55cff7920ac613e",
       "tabbable": null,
       "tooltip": null,
       "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
      }
     },
     "52f5cf2ab88640c8ac72976b5377952d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "55e53dfb8e6f4441aa3b855415362d55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5816c5848bd04b2d8e61f8e122a74da7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c28bdae0174459c85b3779bc000c796": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c7a1a2d55a44188a466dfd49e46adb9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7db14bd075174ef08b0c5c6a53c38a8b",
        "IPY_MODEL_adc90df8403d47e984c2b08c36f3b04d",
        "IPY_MODEL_3ec55fa1d7574d8297e9f8b99e377856"
       ],
       "layout": "IPY_MODEL_5e4fe62589e94835b3f4f23f94467539",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5e4fe62589e94835b3f4f23f94467539": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f9ca79074174b6589ce972182b965f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "TextStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "TextStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "63420c59b0164cc498e016570df274ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6688a223db0d47cd94d372a205230081": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "68548c1ccbcf4a0f9c62ea698af8dfe6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4cd05581ab1640a8a2eabc82472f8708",
       "max": 21954601.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0bb595a1934147f9907fe6e8de8cd556",
       "tabbable": null,
       "tooltip": null,
       "value": 21954601.0
      }
     },
     "6c4f8f40beed434abaa1b7186828ce5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "CheckboxStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "CheckboxStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": ""
      }
     },
     "72b68f977b514515bae5c6ef23fdb2e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "75ed79570f5e4a6e878c3bdd76c8d78f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7b5f5b8cad5d430a874946917be92a05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b02518e51f9f46da837e3723bf08ac72",
        "IPY_MODEL_68548c1ccbcf4a0f9c62ea698af8dfe6",
        "IPY_MODEL_b7b923190afe4da182d3b80380ae39f2"
       ],
       "layout": "IPY_MODEL_025791f3dafa4d2898ed219b0133726f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7db14bd075174ef08b0c5c6a53c38a8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_33d6ab90aeb34130a61dcb8f24935227",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_81d832d22bfe447f892dce1191aab486",
       "tabbable": null,
       "tooltip": null,
       "value": "Computing‚Äáchecksums:‚Äá100%"
      }
     },
     "802bb49cac5042dfa0bbfeed5e3bc891": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81d832d22bfe447f892dce1191aab486": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "876a40e482d4442d94b8268a50e78002": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "894192aac2f044bb883b6b8c86bedb87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c57c81781824e86a169eeb2fa332b6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ec278ae963d4fc9963a5feaa88c5959": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9dabd4bde00248ecb49bd3596e5f1f9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a478ccf3804d4b4fa55cff7920ac613e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a6611c557aba4d21b0275d908c4b9071": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aafb4544617f4d3cb7fe191b704f0cce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac4a9bbf31a94613ba350322d2450aef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": "center",
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "flex",
       "flex": null,
       "flex_flow": "column",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "50%"
      }
     },
     "ada6e0f671ec41ca84eb5420051e6625": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "adc90df8403d47e984c2b08c36f3b04d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c4a774ad000a4e5ba0b1dfc824f11be0",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_63420c59b0164cc498e016570df274ca",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "af1fb63fbf1e44fc818abe30b3950137": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afdc9d5742ea4a5cbfa71d4b07c9a223": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "CheckboxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "CheckboxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "CheckboxView",
       "description": "Add token as git credential?",
       "description_allow_html": false,
       "disabled": false,
       "indent": true,
       "layout": "IPY_MODEL_8ec278ae963d4fc9963a5feaa88c5959",
       "style": "IPY_MODEL_6c4f8f40beed434abaa1b7186828ce5d",
       "tabbable": null,
       "tooltip": null,
       "value": true
      }
     },
     "b02518e51f9f46da837e3723bf08ac72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c57c81781824e86a169eeb2fa332b6d",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_6688a223db0d47cd94d372a205230081",
       "tabbable": null,
       "tooltip": null,
       "value": "huggingface_doc.csv:‚Äá100%"
      }
     },
     "b7b923190afe4da182d3b80380ae39f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_aafb4544617f4d3cb7fe191b704f0cce",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_2290154d282745ee80914930e34e6ac7",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá22.0M/22.0M‚Äá[00:00&lt;00:00,‚Äá25.2MB/s]"
      }
     },
     "c4a774ad000a4e5ba0b1dfc824f11be0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c755d5412b5c4136811152c6f144382b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c87abe87349649d4b5d5365719b60b92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ca0f4d9eecde4f799df8935de1da207e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ca74af4920944e6481d85516570e5a03": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb168b90804f4dce92fe8e20fd3e22c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d026dd30d0d540128ffc01fba36d9def": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1bf06ef371f54d1a95e999113a945edf",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_c87abe87349649d4b5d5365719b60b92",
       "tabbable": null,
       "tooltip": null,
       "value": "README.md:‚Äá100%"
      }
     },
     "d3b3a6a27bae46bdae8c182955ef2180": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_75ed79570f5e4a6e878c3bdd76c8d78f",
       "max": 2647.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ca0f4d9eecde4f799df8935de1da207e",
       "tabbable": null,
       "tooltip": null,
       "value": 2647.0
      }
     },
     "d51a217ab03543a89c2566e1844ef8a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5c28bdae0174459c85b3779bc000c796",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_403266b8921a4369962d70a5e261f8ce",
       "tabbable": null,
       "tooltip": null,
       "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
      }
     },
     "d5c9bfaa6cc947c495f67c78fa131e11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fcc3e7be45614015b63a9b66675ae531",
        "IPY_MODEL_26bc766c13fd4042ae866da719227613",
        "IPY_MODEL_afdc9d5742ea4a5cbfa71d4b07c9a223",
        "IPY_MODEL_0c7ba9bbd36d47d8bd1dd68a62eec7f4",
        "IPY_MODEL_51d3d2e2b1f9450086aed38ed6248824"
       ],
       "layout": "IPY_MODEL_ac4a9bbf31a94613ba350322d2450aef",
       "tabbable": null,
       "tooltip": null
      }
     },
     "dbc460d7eaf549b697061cee9d5a81ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_52f5cf2ab88640c8ac72976b5377952d",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_486e25d76dfe4c83bb55e087f89099b8",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá2647/2647‚Äá[00:00&lt;00:00,‚Äá5938.47‚Äáexamples/s]"
      }
     },
     "df408e45a1a94628a75cdea677ebe43d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_25e91fc16cbf488f99a811af4ffaa7c8",
        "IPY_MODEL_d3b3a6a27bae46bdae8c182955ef2180",
        "IPY_MODEL_1a1b3ca616154088a32e870f3cffaf35"
       ],
       "layout": "IPY_MODEL_4e142e755c1f43ab93acc81541c243bd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e96841e6807d4c528a630579936d5b99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f981210c326f4846b0c3d863063c8db2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d026dd30d0d540128ffc01fba36d9def",
        "IPY_MODEL_42c6db21af3c49b1b37609a15c4422f1",
        "IPY_MODEL_30e9f14fb9ce4bc2ad8d208f6b150ec0"
       ],
       "layout": "IPY_MODEL_5816c5848bd04b2d8e61f8e122a74da7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "fcc3e7be45614015b63a9b66675ae531": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_479929f998d844a7b1213c9251e0712f",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_9dabd4bde00248ecb49bd3596e5f1f9d",
       "tabbable": null,
       "tooltip": null,
       "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
      }
     },
     "fe311916ec46425ebd8f64f4be71f561": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
